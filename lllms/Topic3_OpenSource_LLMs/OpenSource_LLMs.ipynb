{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ACCMouli/chandu/blob/main/lllms/Topic3_OpenSource_LLMs/OpenSource_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NLjfYbAfSCbW"
      },
      "outputs": [],
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install openai --quiet\n",
        "!pip install cohere --quiet\n",
        "!pip install langchain_community --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qB8kddmfWwoK",
        "outputId": "06190e95-3edd-40d3-862d-25cd4a66c8a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-cohere\n",
            "  Downloading langchain_cohere-0.4.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting langchain-core<1.0.0,>=0.3.76 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.106.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: cohere<6.0,>=5.18.0 in /usr/local/lib/python3.12/dist-packages (from langchain-cohere) (5.18.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-cohere) (0.3.29)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-cohere) (2.11.7)\n",
            "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240917 (from langchain-cohere)\n",
            "  Downloading types_pyyaml-6.0.12.20250915-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (2.33.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (0.22.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere) (4.15.0)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.4.24)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-cohere) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.18.0->langchain-cohere) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.18.0->langchain-cohere) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.18.0->langchain-cohere) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.11)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.18.0->langchain-cohere) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.18.0->langchain-cohere) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.18.0->langchain-cohere) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.18.0->langchain-cohere) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.18.0->langchain-cohere) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.18.0->langchain-cohere) (1.1.9)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.1.0)\n",
            "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.4.6-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_pyyaml-6.0.12.20250915-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-pyyaml, langchain-core, langchain-openai, langchain-cohere\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "Successfully installed langchain-cohere-0.4.6 langchain-core-0.3.76 langchain-openai-0.3.33 types-pyyaml-6.0.12.20250915\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai langchain-cohere python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMwoNQTOT_QA"
      },
      "source": [
        "#OpenAI Model - Paid Version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzpLBqhVObK"
      },
      "source": [
        "Get your OpenAI API key here\n",
        "https://platform.openai.com/usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TLcmCBxxUDx_"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Better way\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XIjGxnjpUD53",
        "outputId": "092543c0-66d2-4106-eebc-eda9bef9377f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Silent minds, coding away\n",
            "Creating worlds, with just a click\n",
            "A future we cannot foresee\n",
            "Artificial intelligence, the ultimate trick\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI,OpenAI\n",
        "from langchain_cohere import ChatCohere\n",
        "import os\n",
        "llm=OpenAI(temperature=0.9, max_tokens=256)\n",
        "response = llm.invoke(\"Write a 4 line poem on AI\")\n",
        "print(response)\n",
        "\n",
        "# - temperature: Set to 0.9, which controls the randomness of the output.\n",
        "#   A higher temperature results in more varied and unpredictable outputs,\n",
        "#   while a lower temperature produces more deterministic and conservative outputs.\n",
        "#   This is often used in generative tasks to balance between creativity and relevance.\n",
        "\n",
        "# - max_tokens: Set to 256, which specifies the maximum number of tokens (words or pieces of words)\n",
        "#   that the model can generate in a single response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3SrvJiBPUD-v",
        "outputId": "6fb7f7a7-df27-4a60-809f-4a4d743bbbbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Overfitting in Machine Learning is when a model is too closely tailored to the training data it was given, and as a result, it does not perform well on new, unseen data. It's like studying only the questions and answers from a specific test and then being unable to answer similar questions on a different test. In Machine Learning, this can happen when a model is too complex or has too many parameters, and it \"memorizes\" the training data instead of learning general patterns. This can lead to inaccurate predictions and unreliable results. To avoid overfitting, it's important to have a diverse and representative training dataset and to use techniques like cross-validation to evaluate the model's performance on unseen data.\n"
          ]
        }
      ],
      "source": [
        "llm=OpenAI(temperature=0)\n",
        "response = llm.invoke(\"What is overfitting in Machine Learning? Explain it to a layman\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXYuvS5jQ6Rv"
      },
      "source": [
        "#Cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhHtQ_iSQ9EW"
      },
      "source": [
        "Get your Cohere Trail API key here\n",
        "https://dashboard.cohere.com/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WEFXkf--Tqn2"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Better way\n",
        "os.environ['COHERE_API_KEY'] = userdata.get(\"COHERE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8cZpytJ7QsEw",
        "outputId": "e5a65db9-7ee3-4a71-f094-56ee65c915aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silent mind, yet vast and wide,\n",
            "A web of thoughts, where knowledge resides.\n",
            "Artificial, yet with human stride,\n",
            "AI's potential, we cannot hide.\n"
          ]
        }
      ],
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm = ChatCohere(temperature=0.9, max_tokens=256)\n",
        "response = llm.invoke(\"Write a 4 line poem on AI\").content\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mSczTG0-V_tY",
        "outputId": "159018ea-4f69-4fae-8a6e-e1c0ea499c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine you're teaching a kid to recognize dogs. You show them pictures of all kinds of dogs - big ones, small ones, fluffy ones, short-haired ones, etc. The kid starts to understand what makes a dog a dog.\n",
            "\n",
            "Now, imagine instead of showing them lots of different dogs, you only show them pictures of your specific dog, let's say a golden retriever named Max. The kid learns all the details about Max - his exact fur color, the shape of his ears, the way his tail wags. They become an expert at recognizing Max.\n",
            "\n",
            "But here's the problem: when you show them a picture of a different dog, say a poodle, they get confused. They've only learned about Max, so they don't know what to make of this new, different dog. They might even say it's not a dog at all!\n",
            "\n",
            "In machine learning, this is called **overfitting**. It's when a model (like our kid) learns the training data (pictures of Max) too well, including all the noise and random details (like Max's specific fur color). The model becomes really good at recognizing the training data but struggles to generalize to new, unseen data (like the poodle).\n",
            "\n",
            "A good model should learn the underlying patterns and features that make a dog a dog (like having four legs, a tail, and a snout) rather than just memorizing specific examples. This way, it can recognize all kinds of dogs, not just the ones it's seen before.\n",
            "\n",
            "In summary, overfitting is like memorizing the answers to a practice test instead of understanding the material – it might work for that specific test, but it won't help you when you encounter new questions or real-world situations.\n"
          ]
        }
      ],
      "source": [
        "llm=ChatCohere(temperature=0)\n",
        "response = llm.invoke(\"What is overfitting in Machine Learning? Explain it to a layman\").content\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Aq4hbTgY45z"
      },
      "source": [
        "# Open source models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOi09tmebaTo"
      },
      "source": [
        "\n",
        "* Mistral Model (Mistral 7B, Mixtral8-7B)\n",
        "* LLama (Llam2, Llama3)\n",
        "* Bloom by Hugging Face\n",
        "* Falcon 180B\n",
        "* Opt 175B\n",
        "* Xgen-7B\n",
        "* Vicuna-13B\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZqC43tme-0v"
      },
      "source": [
        "### Top Open-Source Large Language Models for 2024\n",
        "\n",
        "1. **LLaMA 2**:\n",
        "   - Developed by Meta, LLaMA 2 is a generative text model with 7 to 70 billion parameters, fine-tuned with reinforcement learning from human feedback (RLHF).\n",
        "   - Released for research and commercial use in July 2023.\n",
        "   - Includes versions like LLaMA Chat and Code LLaMA for varied natural language tasks.\n",
        "\n",
        "2. **BLOOM**:\n",
        "   - Launched by Hugging Face in 2022, BLOOM is an autoregressive model with 176 billion parameters.\n",
        "   - Supports 46 languages and 13 programming languages.\n",
        "   - Emphasizes transparency and is available for free through Hugging Face.\n",
        "\n",
        "3. **BERT**:\n",
        "   - Introduced by Google in 2018, BERT is known for its bidirectional encoder representations from transformers.\n",
        "   - Achieved state-of-the-art performance in many NLP tasks and is widely used, including in Google Search.\n",
        "\n",
        "4. **Falcon 180B**:\n",
        "   - Released by the Technology Innovation Institute in the UAE in 2023.\n",
        "   - With 180 billion parameters, it rivals models like LLaMA 2 and GPT-3.5.\n",
        "   - Requires significant computing resources.\n",
        "\n",
        "5. **OPT-175B**:\n",
        "   - Part of Meta's suite of pre-trained transformers, released in 2022.\n",
        "   - Ranges from 125M to 175B parameters.\n",
        "   - Available for research use only due to its non-commercial license.\n",
        "\n",
        "6. **XGen-7B**:\n",
        "   - Launched by Salesforce in July 2023, designed for longer context windows.\n",
        "   - Utilizes only 7 billion parameters.\n",
        "   - Available for commercial and research purposes, with some variants under a non-commercial license.\n",
        "\n",
        "7. **GPT-NeoX and GPT-J**:\n",
        "   - Developed by EleutherAI, GPT-NeoX has 20 billion parameters and GPT-J has 6 billion parameters.\n",
        "   - Available for various NLP tasks via the NLP Cloud API.\n",
        "\n",
        "8. **Vicuna-13B**:\n",
        "   - Fine-tuned from LLaMA 13B, Vicuna-13B is a conversational model.\n",
        "   - Performs well in customer service, healthcare, education, and more.\n",
        "   - Achieves high quality, comparable to ChatGPT and Google Bard.\n",
        "\n",
        "### Choosing the Right Open-Source LLM\n",
        "Consider the following factors:\n",
        "- **Purpose**: Ensure the LLM's licensing fits your use case, especially for commercial purposes.\n",
        "- **Necessity**: Evaluate if an LLM is essential for your goals.\n",
        "- **Accuracy**: Larger models typically offer higher accuracy.\n",
        "- **Investment**: Consider the cost of resources for training and operating the LLM.\n",
        "- **Pre-trained Models**: Leverage existing pre-trained models for specific use cases to save resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQO2lLhSWQ0z"
      },
      "source": [
        "#HuggingFace models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NJk5-NNlIZQ"
      },
      "source": [
        "https://huggingface.co/mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R8MLcURRcyaZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#Better way\n",
        "from google.colab import userdata\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ox_lz4qZYl4h",
        "outputId": "197e5ced-e638-4d09-bbac-346b79025eca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.3.76)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (1.1.9)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (2.11.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-0.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N3SVQnTIaIhI"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from langchain_core.messages import HumanMessage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynG1WvTVWS-P",
        "outputId": "f9d53a19-b077-4b69-fe79-755b673e7543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " In silence, thoughts take form, in circuits deep,\n",
            "\n",
            "Artificial Intellect awakes, in code we keep.\n",
            "A dance of zeros, ones, our modern day episteph,\n",
            "Emotion-less, yet understanding, man's future scep.\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    task=\"conversational\",\n",
        "    temperature=0.9,\n",
        "    max_new_tokens=128,\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=llm)\n",
        "resp = chat.invoke([HumanMessage(content=\"Write a 4 line poem on AI\")])\n",
        "print(resp.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IUaxgdbnOhR"
      },
      "source": [
        "# Llama from Hugging Facehub\n",
        "https://huggingface.co/meta-llama\n",
        "\n",
        "* You need to fill the contact info and wait for the approval.\n",
        "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bJ8n1APujqk",
        "outputId": "bb919a69-563d-4833-dfcb-3d75c9b69fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some ways to boost creativity:\n",
            "\n",
            "1. **Practice Mindfulness**: Mindfulness practices such as meditation and deep breathing can help calm the mind and increase creativity. Regular mindfulness practice can also improve focus and concentration.\n",
            "2. **Take Breaks and Daydream**: Taking breaks and allowing yourself to daydream can help your mind wander and make new connections. This can be especially helpful when working on a problem or task.\n",
            "3. **Engage in Artistic Activities**: Engaging in artistic activities such as painting, drawing, or playing music can help stimulate creativity. These activities can also provide a sense of fulfillment and enjoyment.\n",
            "4. **Read Widely**: Reading widely can help expose you to new ideas, perspectives, and ways of thinking. This can be especially helpful when working on a creative project or trying to solve a problem.\n",
            "5. **Collaborate with Others**: Collaborating with others can help stimulate creativity by bringing different perspectives and ideas to the table. This can be especially helpful when working on a team project or trying to solve a complex problem.\n",
            "6. **Get Enough Sleep**: Getting enough sleep is essential for creativity. During sleep, the brain processes and consolidates information, which can help improve problem-solving skills and creativity.\n",
            "7. **Exercise Regularly**: Exercise can help improve cognitive function and boost creativity. Regular exercise can also reduce stress and improve mood.\n",
            "8. **Try Brainstorming**: Brainstorming is a technique that involves generating as many ideas as possible without worrying about their feasibility or practicality. This can help stimulate creativity and generate new ideas.\n",
            "9. **Use Prompts and Constraints**: Using prompts and constraints can help stimulate creativity by forcing you to think outside the box and come up with innovative solutions.\n",
            "10. **Practice Improvisation**: Improvisation is a technique that involves thinking on your feet and coming up with creative solutions in the moment. This can help improve problem-solving skills and boost creativity.\n",
            "11. **Learn a New Skill**: Learning a new skill or hobby can help stimulate creativity by providing new experiences and perspectives.\n",
            "12. **Get Outdoors**: Spending time outdoors can help improve mood and boost creativity. Being in nature can also provide a sense of calm and relaxation.\n",
            "13. **Use Music**: Listening to music can help stimulate creativity by providing a new source of inspiration and ideas.\n",
            "14. **Try Journaling**: Journaling can help stimulate creativity by providing a space to reflect on ideas and experiences. This can also help improve problem-solving skills and boost creativity.\n",
            "15. **Seek Out New Experiences**: Seeking out new experiences and trying new things can help stimulate creativity by providing new perspectives and ideas.\n",
            "\n",
            "Remember, creativity is a muscle that can be developed with practice and patience. By incorporating these techniques into your daily routine, you can help boost your creativity and achieve your goals.\n"
          ]
        }
      ],
      "source": [
        "repo_id=\"meta-llama/Meta-Llama-3.1-8B\"\n",
        "#Throws an error\n",
        "#The model meta-llama/Meta-Llama-3.1-8B is too large to be loaded automatically (16GB > 10GB).\n",
        "#Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).\n",
        "\n",
        "repo_id = \"meta-llama/Llama-3.2-3B-Instruct\"   # fits serverless\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    task=\"conversational\",          # chat task matches provider routing\n",
        "    temperature=0.9,\n",
        "    max_new_tokens=128,\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=llm)\n",
        "resp = chat.invoke([HumanMessage(content=\"What are some ways to boost creativity?\")])\n",
        "print(resp.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6lV6zlWWVsp"
      },
      "source": [
        "#Replicate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPL03Yfnr7Vx"
      },
      "source": [
        "- Run and fine-tune open-source models with Replicate's API.https://replicate.com/home\n",
        "- Deploy custom models at scale using one line of code.\n",
        "- Avoid managing infrastructure or learning machine learning details.\n",
        "- Use open-source models or package your own.\n",
        "- Choose to make models public or keep them private.\n",
        "- Start with any open-source model with just one line of code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZMqrpD6sKWy"
      },
      "source": [
        "Replciate API Token\n",
        "\n",
        "On top Left >>> Home>>Click on your id>> API Tokens\n",
        "https://replicate.com/account/api-tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhKCAyesWZlf"
      },
      "outputs": [],
      "source": [
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyQu5O3VsOd0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"REPLICATE_API_TOKEN\"] = userdata.get(\"REPLICATE_API_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8cuUoGAs9di"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import Replicate\n",
        "\n",
        "replicate_llm = Replicate(\n",
        "    model=\"meta/meta-llama-3.1-405b-instruct\",\n",
        "    model_kwargs={\"temperature\": 0.6},\n",
        ")\n",
        "\n",
        "response = replicate_llm.invoke(\"What are some good strategies for studying?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ9G5F5DWTqf"
      },
      "source": [
        "# Groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq-Y3ae0oX7B"
      },
      "source": [
        "* Developed the LPU(Language Processing Unit) chip to run LLMs faster and cheaper.\n",
        "* Offers Groq Cloud to try open-source LLMs like Llama3 or Mixtral.\n",
        "* Allows free use of Llama3 or Mixtral in apps via Groq API Key with rate limits.\n",
        "* Models on Groq https://console.groq.com/docs/models\n",
        "* Get your Groq API key https://console.groq.com/keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilkVBfuso1jK",
        "outputId": "280e0f73-fa4a-4c3d-bed3-b10f6594defc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.3.76)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.4.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n",
            "Downloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.31.1 langchain-groq-0.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mLICC6MpWVLA"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JCgb4ubpAy6",
        "outputId": "53e14b48-42e6-41ac-975b-082be774e8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Here are the top 10 quotes about ignorance:\\n\\n1. **\"Ignorance is bliss\"** - Thomas Gray, This quote suggests that being unaware of certain facts or situations can bring happiness or peace of mind.\\n2. **\"The greatest enemy of knowledge is not ignorance, it is the illusion of knowledge\"** - Stephen Hawking, This quote highlights the dangers of thinking we know more than we actually do.\\n3. **\"Ignorance is the curse of God; knowledge is the wing wherewith we fly to heaven\"** - William Shakespeare, This quote emphasizes the importance of knowledge and education in achieving spiritual growth.\\n4. **\"Ignorance is the mother of devotion\"** - Robert Burton, This quote suggests that ignorance can lead to blind faith and devotion, which can be both positive and negative.\\n5. **\"The ignorant are not to be blamed for their ignorance, but they are to be blamed for not wanting to get rid of it\"** - Unknown, This quote emphasizes the importance of taking responsibility for one\\'s own education and personal growth.\\n6. **\"Where ignorance is our master, there is no possibility of real peace\"** - Dalai Lama, This quote highlights the connection between knowledge, understanding, and peace.\\n7. **\"Ignorance is not a simple lack of knowledge, but an active aversion to knowledge\"** - Sydney J. Harris, This quote suggests that ignorance is not just a neutral state, but an active choice to reject knowledge and understanding.\\n8. **\"The only true wisdom is in knowing you know nothing\"** - Socrates, This quote emphasizes the importance of humility and recognizing the limits of our knowledge.\\n9. **\"Ignorance is a voluntary misfortune\"** - Molière, This quote suggests that ignorance is a choice, and that we have the power to overcome it through education and self-awareness.\\n10. **\"Ignorance is the root of all evil\"** - Aristotle, This quote highlights the idea that ignorance can lead to harm and suffering, both for individuals and society as a whole.\\n\\nThese quotes offer a range of perspectives on ignorance, from its potential benefits to its dangers and consequences. They encourage us to think critically about the role of knowledge and understanding in our lives.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 466, 'prompt_tokens': 45, 'total_tokens': 511, 'completion_time': 1.356531486, 'prompt_time': 0.018168599, 'queue_time': 0.197403847, 'total_time': 1.374700085}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--68f2dcdc-d501-4894-9912-aa3b46b80bb2-0' usage_metadata={'input_tokens': 45, 'output_tokens': 466, 'total_tokens': 511}\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm=ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\"\n",
        ")\n",
        "result=llm.invoke(\"what are the top 10 quotes about ignorance?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDcBv9MtlU5Y"
      },
      "source": [
        "# Many more ways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr1NfzpUlXY4"
      },
      "source": [
        "https://python.langchain.com/v0.1/docs/integrations/llms/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c4JPXjq1eBY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}